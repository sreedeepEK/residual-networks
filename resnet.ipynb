{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This repository contains the implementation of the original ResNet research paper. \n",
    "In this notebook, you can find the layers of architecture i've built. For more info about the reserch paper, [click here!](https://arxiv.org/pdf/1512.03385)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#import libraries \n",
    "\n",
    "import os\n",
    "import torch \n",
    "import torchinfo\n",
    "import torch.nn as nn  \n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual block is a type of neural network layer that allows gradients\n",
    "to flow more easily during backpropagation, facilitating the training of\n",
    "deeper networks. The primary concept is to use a shortcut connection that\n",
    "bypasses one or more layers, enabling the network to learn residual function.\n",
    "\n",
    "![alttext](images/residual_vgg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,472\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "            Conv2d-4         [-1, 64, 112, 112]           4,160\n",
      "       BatchNorm2d-5         [-1, 64, 112, 112]             128\n",
      "              ReLU-6         [-1, 64, 112, 112]               0\n",
      "            Conv2d-7         [-1, 64, 112, 112]          36,928\n",
      "       BatchNorm2d-8         [-1, 64, 112, 112]             128\n",
      "              ReLU-9         [-1, 64, 112, 112]               0\n",
      "           Conv2d-10        [-1, 256, 112, 112]          16,640\n",
      "      BatchNorm2d-11        [-1, 256, 112, 112]             512\n",
      "           Conv2d-12        [-1, 256, 112, 112]          16,640\n",
      "      BatchNorm2d-13        [-1, 256, 112, 112]             512\n",
      "             ReLU-14        [-1, 256, 112, 112]               0\n",
      "            Block-15        [-1, 256, 112, 112]               0\n",
      "           Conv2d-16         [-1, 64, 112, 112]          16,448\n",
      "      BatchNorm2d-17         [-1, 64, 112, 112]             128\n",
      "             ReLU-18         [-1, 64, 112, 112]               0\n",
      "           Conv2d-19         [-1, 64, 112, 112]          36,928\n",
      "      BatchNorm2d-20         [-1, 64, 112, 112]             128\n",
      "             ReLU-21         [-1, 64, 112, 112]               0\n",
      "           Conv2d-22        [-1, 256, 112, 112]          16,640\n",
      "      BatchNorm2d-23        [-1, 256, 112, 112]             512\n",
      "             ReLU-24        [-1, 256, 112, 112]               0\n",
      "            Block-25        [-1, 256, 112, 112]               0\n",
      "           Conv2d-26         [-1, 64, 112, 112]          16,448\n",
      "      BatchNorm2d-27         [-1, 64, 112, 112]             128\n",
      "             ReLU-28         [-1, 64, 112, 112]               0\n",
      "           Conv2d-29         [-1, 64, 112, 112]          36,928\n",
      "      BatchNorm2d-30         [-1, 64, 112, 112]             128\n",
      "             ReLU-31         [-1, 64, 112, 112]               0\n",
      "           Conv2d-32        [-1, 256, 112, 112]          16,640\n",
      "      BatchNorm2d-33        [-1, 256, 112, 112]             512\n",
      "             ReLU-34        [-1, 256, 112, 112]               0\n",
      "            Block-35        [-1, 256, 112, 112]               0\n",
      "           Conv2d-36        [-1, 128, 112, 112]          32,896\n",
      "      BatchNorm2d-37        [-1, 128, 112, 112]             256\n",
      "             ReLU-38        [-1, 128, 112, 112]               0\n",
      "           Conv2d-39          [-1, 128, 56, 56]         147,584\n",
      "      BatchNorm2d-40          [-1, 128, 56, 56]             256\n",
      "             ReLU-41          [-1, 128, 56, 56]               0\n",
      "           Conv2d-42          [-1, 512, 56, 56]          66,048\n",
      "      BatchNorm2d-43          [-1, 512, 56, 56]           1,024\n",
      "           Conv2d-44          [-1, 512, 56, 56]         131,584\n",
      "      BatchNorm2d-45          [-1, 512, 56, 56]           1,024\n",
      "             ReLU-46          [-1, 512, 56, 56]               0\n",
      "            Block-47          [-1, 512, 56, 56]               0\n",
      "           Conv2d-48          [-1, 128, 56, 56]          65,664\n",
      "      BatchNorm2d-49          [-1, 128, 56, 56]             256\n",
      "             ReLU-50          [-1, 128, 56, 56]               0\n",
      "           Conv2d-51          [-1, 128, 56, 56]         147,584\n",
      "      BatchNorm2d-52          [-1, 128, 56, 56]             256\n",
      "             ReLU-53          [-1, 128, 56, 56]               0\n",
      "           Conv2d-54          [-1, 512, 56, 56]          66,048\n",
      "      BatchNorm2d-55          [-1, 512, 56, 56]           1,024\n",
      "             ReLU-56          [-1, 512, 56, 56]               0\n",
      "            Block-57          [-1, 512, 56, 56]               0\n",
      "           Conv2d-58          [-1, 128, 56, 56]          65,664\n",
      "      BatchNorm2d-59          [-1, 128, 56, 56]             256\n",
      "             ReLU-60          [-1, 128, 56, 56]               0\n",
      "           Conv2d-61          [-1, 128, 56, 56]         147,584\n",
      "      BatchNorm2d-62          [-1, 128, 56, 56]             256\n",
      "             ReLU-63          [-1, 128, 56, 56]               0\n",
      "           Conv2d-64          [-1, 512, 56, 56]          66,048\n",
      "      BatchNorm2d-65          [-1, 512, 56, 56]           1,024\n",
      "             ReLU-66          [-1, 512, 56, 56]               0\n",
      "            Block-67          [-1, 512, 56, 56]               0\n",
      "           Conv2d-68          [-1, 128, 56, 56]          65,664\n",
      "      BatchNorm2d-69          [-1, 128, 56, 56]             256\n",
      "             ReLU-70          [-1, 128, 56, 56]               0\n",
      "           Conv2d-71          [-1, 128, 56, 56]         147,584\n",
      "      BatchNorm2d-72          [-1, 128, 56, 56]             256\n",
      "             ReLU-73          [-1, 128, 56, 56]               0\n",
      "           Conv2d-74          [-1, 512, 56, 56]          66,048\n",
      "      BatchNorm2d-75          [-1, 512, 56, 56]           1,024\n",
      "             ReLU-76          [-1, 512, 56, 56]               0\n",
      "            Block-77          [-1, 512, 56, 56]               0\n",
      "           Conv2d-78          [-1, 256, 56, 56]         131,328\n",
      "      BatchNorm2d-79          [-1, 256, 56, 56]             512\n",
      "             ReLU-80          [-1, 256, 56, 56]               0\n",
      "           Conv2d-81          [-1, 256, 28, 28]         590,080\n",
      "      BatchNorm2d-82          [-1, 256, 28, 28]             512\n",
      "             ReLU-83          [-1, 256, 28, 28]               0\n",
      "           Conv2d-84         [-1, 1024, 28, 28]         263,168\n",
      "      BatchNorm2d-85         [-1, 1024, 28, 28]           2,048\n",
      "           Conv2d-86         [-1, 1024, 28, 28]         525,312\n",
      "      BatchNorm2d-87         [-1, 1024, 28, 28]           2,048\n",
      "             ReLU-88         [-1, 1024, 28, 28]               0\n",
      "            Block-89         [-1, 1024, 28, 28]               0\n",
      "           Conv2d-90          [-1, 256, 28, 28]         262,400\n",
      "      BatchNorm2d-91          [-1, 256, 28, 28]             512\n",
      "             ReLU-92          [-1, 256, 28, 28]               0\n",
      "           Conv2d-93          [-1, 256, 28, 28]         590,080\n",
      "      BatchNorm2d-94          [-1, 256, 28, 28]             512\n",
      "             ReLU-95          [-1, 256, 28, 28]               0\n",
      "           Conv2d-96         [-1, 1024, 28, 28]         263,168\n",
      "      BatchNorm2d-97         [-1, 1024, 28, 28]           2,048\n",
      "             ReLU-98         [-1, 1024, 28, 28]               0\n",
      "            Block-99         [-1, 1024, 28, 28]               0\n",
      "          Conv2d-100          [-1, 256, 28, 28]         262,400\n",
      "     BatchNorm2d-101          [-1, 256, 28, 28]             512\n",
      "            ReLU-102          [-1, 256, 28, 28]               0\n",
      "          Conv2d-103          [-1, 256, 28, 28]         590,080\n",
      "     BatchNorm2d-104          [-1, 256, 28, 28]             512\n",
      "            ReLU-105          [-1, 256, 28, 28]               0\n",
      "          Conv2d-106         [-1, 1024, 28, 28]         263,168\n",
      "     BatchNorm2d-107         [-1, 1024, 28, 28]           2,048\n",
      "            ReLU-108         [-1, 1024, 28, 28]               0\n",
      "           Block-109         [-1, 1024, 28, 28]               0\n",
      "          Conv2d-110          [-1, 256, 28, 28]         262,400\n",
      "     BatchNorm2d-111          [-1, 256, 28, 28]             512\n",
      "            ReLU-112          [-1, 256, 28, 28]               0\n",
      "          Conv2d-113          [-1, 256, 28, 28]         590,080\n",
      "     BatchNorm2d-114          [-1, 256, 28, 28]             512\n",
      "            ReLU-115          [-1, 256, 28, 28]               0\n",
      "          Conv2d-116         [-1, 1024, 28, 28]         263,168\n",
      "     BatchNorm2d-117         [-1, 1024, 28, 28]           2,048\n",
      "            ReLU-118         [-1, 1024, 28, 28]               0\n",
      "           Block-119         [-1, 1024, 28, 28]               0\n",
      "          Conv2d-120          [-1, 256, 28, 28]         262,400\n",
      "     BatchNorm2d-121          [-1, 256, 28, 28]             512\n",
      "            ReLU-122          [-1, 256, 28, 28]               0\n",
      "          Conv2d-123          [-1, 256, 28, 28]         590,080\n",
      "     BatchNorm2d-124          [-1, 256, 28, 28]             512\n",
      "            ReLU-125          [-1, 256, 28, 28]               0\n",
      "          Conv2d-126         [-1, 1024, 28, 28]         263,168\n",
      "     BatchNorm2d-127         [-1, 1024, 28, 28]           2,048\n",
      "            ReLU-128         [-1, 1024, 28, 28]               0\n",
      "           Block-129         [-1, 1024, 28, 28]               0\n",
      "          Conv2d-130          [-1, 256, 28, 28]         262,400\n",
      "     BatchNorm2d-131          [-1, 256, 28, 28]             512\n",
      "            ReLU-132          [-1, 256, 28, 28]               0\n",
      "          Conv2d-133          [-1, 256, 28, 28]         590,080\n",
      "     BatchNorm2d-134          [-1, 256, 28, 28]             512\n",
      "            ReLU-135          [-1, 256, 28, 28]               0\n",
      "          Conv2d-136         [-1, 1024, 28, 28]         263,168\n",
      "     BatchNorm2d-137         [-1, 1024, 28, 28]           2,048\n",
      "            ReLU-138         [-1, 1024, 28, 28]               0\n",
      "           Block-139         [-1, 1024, 28, 28]               0\n",
      "          Conv2d-140          [-1, 512, 28, 28]         524,800\n",
      "     BatchNorm2d-141          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-142          [-1, 512, 28, 28]               0\n",
      "          Conv2d-143          [-1, 512, 14, 14]       2,359,808\n",
      "     BatchNorm2d-144          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-145          [-1, 512, 14, 14]               0\n",
      "          Conv2d-146         [-1, 2048, 14, 14]       1,050,624\n",
      "     BatchNorm2d-147         [-1, 2048, 14, 14]           4,096\n",
      "          Conv2d-148         [-1, 2048, 14, 14]       2,099,200\n",
      "     BatchNorm2d-149         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-150         [-1, 2048, 14, 14]               0\n",
      "           Block-151         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-152          [-1, 512, 14, 14]       1,049,088\n",
      "     BatchNorm2d-153          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-154          [-1, 512, 14, 14]               0\n",
      "          Conv2d-155          [-1, 512, 14, 14]       2,359,808\n",
      "     BatchNorm2d-156          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-157          [-1, 512, 14, 14]               0\n",
      "          Conv2d-158         [-1, 2048, 14, 14]       1,050,624\n",
      "     BatchNorm2d-159         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-160         [-1, 2048, 14, 14]               0\n",
      "           Block-161         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-162          [-1, 512, 14, 14]       1,049,088\n",
      "     BatchNorm2d-163          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-164          [-1, 512, 14, 14]               0\n",
      "          Conv2d-165          [-1, 512, 14, 14]       2,359,808\n",
      "     BatchNorm2d-166          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-167          [-1, 512, 14, 14]               0\n",
      "          Conv2d-168         [-1, 2048, 14, 14]       1,050,624\n",
      "     BatchNorm2d-169         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-170         [-1, 2048, 14, 14]               0\n",
      "           Block-171         [-1, 2048, 14, 14]               0\n",
      "AdaptiveAvgPool2d-172           [-1, 2048, 1, 1]               0\n",
      "          Linear-173                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,583,592\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 1084.91\n",
      "Params size (MB): 97.59\n",
      "Estimated Total Size (MB): 1183.08\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from resnet import resnet50 \n",
    "model = resnet50().to(device)\n",
    "input_size = (3,224,224) #for rbg 224x224\n",
    "\n",
    "from torchsummary import summary\n",
    "a = summary(model,input_size) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alttext](images/res_architecutre.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.size() = torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "     device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "     net = resnet50(img_channels=3, num_classes=10).to(device)\n",
    "     x = torch.randn(2, 3, 224, 224, device=device)\n",
    "\n",
    "     y: torch.Tensor = net(x)\n",
    "     print(f'{y.size() = }') \n",
    "\n",
    "if __name__ == '__main__':\n",
    "     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the shape `torch.Size([2, 10])` indicates that the model produced predictions for 2 input samples, with each sample having 10 potential output classes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudavenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
